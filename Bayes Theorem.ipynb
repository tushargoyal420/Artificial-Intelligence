{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bayes Theorem.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNOw2s0oo7uCODgd5WUKPsf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwnXZIhNUAhx","executionInfo":{"status":"ok","timestamp":1605853322228,"user_tz":-330,"elapsed":38971,"user":{"displayName":"TUSHAR GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyzwdUiA76sATrH1fX_u0-DCBsG0RTgnU__oph=s64","userId":"17352229676142740617"}},"outputId":"ab54824e-4a0b-4bca-8b61-774243a9c961"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVmGmhzQULbM","executionInfo":{"status":"ok","timestamp":1605853436683,"user_tz":-330,"elapsed":1379,"user":{"displayName":"TUSHAR GOYAL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyzwdUiA76sATrH1fX_u0-DCBsG0RTgnU__oph=s64","userId":"17352229676142740617"}},"outputId":"442306aa-977e-4149-d95a-c5cdc2a53eac"},"source":["from csv import reader\n","from random import seed\n","from random import randrange\n","from math import sqrt\n","from math import exp\n","from math import pi\n","\n","filename=\"/content/gdrive/My Drive/filename.txt\"\n","\n","# Load a CSV file\n","def load_csv(filename):\n","\tdataset = list()\n","\twith open(filename, 'r') as file:\n","\t\tcsv_reader = reader(file)\n","\t\tfor row in csv_reader:\n","\t\t\tif not row:\n","\t\t\t\tcontinue\n","\t\t\tdataset.append(row)\n","\treturn dataset\n","\n","# Convert string column to float\n","def str_column_to_float(dataset, column):\n","\tfor row in dataset:\n","\t\trow[column] = float(row[column].strip())\n","\n","# Convert string column to integer\n","def str_column_to_int(dataset, column):\n","\tclass_values = [row[column] for row in dataset]\n","\tunique = set(class_values)\n","\tlookup = dict()\n","\tfor i, value in enumerate(unique):\n","\t\tlookup[value] = i\n","\tfor row in dataset:\n","\t\trow[column] = lookup[row[column]]\n","\treturn lookup\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset, n_folds):\n","\tdataset_split = list()\n","\tdataset_copy = list(dataset)\n","\tfold_size = int(len(dataset) / n_folds)\n","\tfor _ in range(n_folds):\n","\t\tfold = list()\n","\t\twhile len(fold) < fold_size:\n","\t\t\tindex = randrange(len(dataset_copy))\n","\t\t\tfold.append(dataset_copy.pop(index))\n","\t\tdataset_split.append(fold)\n","\treturn dataset_split\n","\n","# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","\tcorrect = 0\n","\tfor i in range(len(actual)):\n","\t\tif actual[i] == predicted[i]:\n","\t\t\tcorrect += 1\n","\treturn correct / float(len(actual)) * 100.0\n","\n","# Evaluate an algorithm using a cross validation split\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","\tfolds = cross_validation_split(dataset, n_folds)\n","\tscores = list()\n","\tfor fold in folds:\n","\t\ttrain_set = list(folds)\n","\t\ttrain_set.remove(fold)\n","\t\ttrain_set = sum(train_set, [])\n","\t\ttest_set = list()\n","\t\tfor row in fold:\n","\t\t\trow_copy = list(row)\n","\t\t\ttest_set.append(row_copy)\n","\t\t\trow_copy[-1] = None\n","\t\tpredicted = algorithm(train_set, test_set, *args)\n","\t\tactual = [row[-1] for row in fold]\n","\t\taccuracy = accuracy_metric(actual, predicted)\n","\t\tscores.append(accuracy)\n","\treturn scores\n","\n","# Split the dataset by class values, returns a dictionary\n","def separate_by_class(dataset):\n","\tseparated = dict()\n","\tfor i in range(len(dataset)):\n","\t\tvector = dataset[i]\n","\t\tclass_value = vector[-1]\n","\t\tif (class_value not in separated):\n","\t\t\tseparated[class_value] = list()\n","\t\tseparated[class_value].append(vector)\n","\treturn separated\n","\n","# Calculate the mean of a list of numbers\n","def mean(numbers):\n","\treturn sum(numbers)/float(len(numbers))\n","\n","# Calculate the standard deviation of a list of numbers\n","def stdev(numbers):\n","\tavg = mean(numbers)\n","\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n","\treturn sqrt(variance)\n","\n","# Calculate the mean, stdev and count for each column in a dataset\n","def summarize_dataset(dataset):\n","\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n","\tdel(summaries[-1])\n","\treturn summaries\n","\n","# Split dataset by class then calculate statistics for each row\n","def summarize_by_class(dataset):\n","\tsepar\n","\n","\n","# Split the dataset by class values, returns a dictionary\n","def separate_by_class(dataset):\n","\tseparated = dict()\n","\tfor i in range(len(dataset)):\n","\t\tvector = dataset[i]\n","\t\tclass_value = vector[-1]\n","\t\tif (class_value not in separated):\n","\t\t\tseparated[class_value] = list()\n","\t\tseparated[class_value].append(vector)\n","\treturn separated\n","\n","# Calculate the mean of a list of numbers\n","def mean(numbers):\n","\treturn sum(numbers)/float(len(numbers))\n","\n","# Calculate the standard deviation of a list of numbers\n","def stdev(numbers):\n","\tavg = mean(numbers)\n","\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n","\treturn sqrt(variance)\n","\n","# Calculate the mean, stdev and count for each column in a dataset\n","def summarize_dataset(dataset):\n","\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n","\tdel(summaries[-1])\n","\treturn summaries\n","\n","\n","# Split dataset by class then calculate statistics for each row\n","def summarize_by_class(dataset):\n","\tseparated = separate_by_class(dataset)\n","\tsummaries = dict()\n","\tfor class_value, rows in separated.items():\n","\t\tsummaries[class_value] = summarize_dataset(rows)\n","\treturn summaries\n","\n","# Calculate the Gaussian probability distribution function for x\n","def calculate_probability(x, mean, stdev):\n","\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n","\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n","\n","# Calculate the probabilities of predicting each class for a given row\n","def calculate_class_probabilities(summaries, row):\n","\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n","\tprobabilities = dict()\n","\tfor class_value, class_summaries in summaries.items():\n","\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n","\t\tfor i in range(len(class_summaries)):\n","\t\t\tmean, stdev, _ = class_summaries[i]\n","\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n","\treturn probabilities\n","\n","\n","# Predict the class for a given row\n","def predict(summaries, row):\n","\tprobabilities = calculate_class_probabilities(summaries, row)\n","\tbest_label, best_prob = None, -1\n","\tfor class_value, probability in probabilities.items():\n","\t\tif best_label is None or probability > best_prob:\n","\t\t\tbest_prob = probability\n","\t\t\tbest_label = class_value\n","\treturn best_label\n","\n","# Naive Bayes Algorithm\n","def naive_bayes(train, test):\n","\tsummarize = summarize_by_class(train)\n","\tpredictions = list()\n","\tfor row in test:\n","\t\toutput = predict(summarize, row)\n","\t\tpredictions.append(output)\n","\treturn(predictions)\n","\n","# Test Naive Bayes on Iris Dataset\n","seed(1)\n","\n","dataset = load_csv(filename)\n","for i in range(len(dataset[0])-1):\n","\tstr_column_to_float(dataset, i)\n","# convert class column to integers\n","str_column_to_int(dataset, len(dataset[0])-1)\n","# evaluate algorithm\n","n_folds = 5\n","scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n","print('Scores: %s' % scores)\n","print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Scores: [93.33333333333333, 96.66666666666667, 100.0, 93.33333333333333, 93.33333333333333]\n","Mean Accuracy: 95.333%\n"],"name":"stdout"}]}]}